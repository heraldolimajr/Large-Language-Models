{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6c871f7e23d34bce8536de995601b4dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8216a2e792fd48bfb0822cb93e7a7eb1",
              "IPY_MODEL_7af0a1bb6b6142d090ddee3386b749d8",
              "IPY_MODEL_f8162356409f43db90197e39f44a9f07"
            ],
            "layout": "IPY_MODEL_fe5ea8e98b6647919b1c2455e376d7b9"
          }
        },
        "8216a2e792fd48bfb0822cb93e7a7eb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73db6d718a9444d2bd3bcb64e9827ba0",
            "placeholder": "​",
            "style": "IPY_MODEL_044070c9f93b4fb18dd86b701e1e8c29",
            "value": "config.json: 100%"
          }
        },
        "7af0a1bb6b6142d090ddee3386b749d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6ea84f049074dc88ea034fa3dee95c6",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95f9a5c4356a4555a245249ec0a1e471",
            "value": 570
          }
        },
        "f8162356409f43db90197e39f44a9f07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ff02fbc3a4f404da7bab42fcca83de8",
            "placeholder": "​",
            "style": "IPY_MODEL_bb1b6c450a9b4332ae8d5617bfc5bde0",
            "value": " 570/570 [00:00&lt;00:00, 67.5kB/s]"
          }
        },
        "fe5ea8e98b6647919b1c2455e376d7b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73db6d718a9444d2bd3bcb64e9827ba0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "044070c9f93b4fb18dd86b701e1e8c29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6ea84f049074dc88ea034fa3dee95c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95f9a5c4356a4555a245249ec0a1e471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ff02fbc3a4f404da7bab42fcca83de8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb1b6c450a9b4332ae8d5617bfc5bde0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1af1585eeef447f8b5cbd5bcead51b07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4789a855406945b696814b208d90d183",
              "IPY_MODEL_9c423de6b74f4588a0cf215c49cfdfe7",
              "IPY_MODEL_2bee7807e617460f999676f744b949da"
            ],
            "layout": "IPY_MODEL_2739a2ca2b2b4eb2a00d32a200af2b8d"
          }
        },
        "4789a855406945b696814b208d90d183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65e2ddc01fc3410e9be2d106ae517a6d",
            "placeholder": "​",
            "style": "IPY_MODEL_da1dc0ea92a645c187231b122dd701f4",
            "value": "model.safetensors: 100%"
          }
        },
        "9c423de6b74f4588a0cf215c49cfdfe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45ff2c5531d04462ad87dae30b67ed68",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a338569e4e344a6b35590873ee56dc3",
            "value": 440449768
          }
        },
        "2bee7807e617460f999676f744b949da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d33dc9047a17420db6626d5e8e8c7bf2",
            "placeholder": "​",
            "style": "IPY_MODEL_d4dcebcac17d45f78a1ee75d3a9f35bb",
            "value": " 440M/440M [00:03&lt;00:00, 148MB/s]"
          }
        },
        "2739a2ca2b2b4eb2a00d32a200af2b8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65e2ddc01fc3410e9be2d106ae517a6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da1dc0ea92a645c187231b122dd701f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45ff2c5531d04462ad87dae30b67ed68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a338569e4e344a6b35590873ee56dc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d33dc9047a17420db6626d5e8e8c7bf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4dcebcac17d45f78a1ee75d3a9f35bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heraldolimajr/Large-Language-Models/blob/main/Notebooks/BERT_Fine_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercício de Fine Tuning do BERT com PyTorch 🤖🐍🔥\n",
        "Neste exercício, você irá implementar o fine tuning do BERT adicionando Task Head com finalidade de classificação. Sugestões utilizando a biblioteca PyTorch.\n",
        "\n",
        "Conforme visto em sala, o Self-attention é um componente central dos Transformers, as redes neurais que impulsionam os modelos de linguagem modernos como o BERT. Após as camadas de atenção dos modelos, podemos adicionar uma ou mais camadas com a finalidade de executar tarefas específicas.\n",
        "\n",
        "## Contexto\n",
        "Um modelo BERT é um Transformer do tipo Encoder que processa um texto de entrada gerando representações semânticas desse texto. O Self-attention permite que o modelo determine a relação entre diferentes tokens em uma sequência.\n",
        "\n",
        "Adicionaremos, conforme visto em sala de aula, Task Head ao modelo para fazer fine tuning de classificação.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### [<img src=\"https://colab.google/static/images/icons/colab.png\" width=100> OPCIONAL ] Configuração do ambiente para melhor desempenho e instalação de dependências\n",
        "💡 **Obs**: Selecione um ambiente com GPU para rodar esse notebook. No Google Colab:\n",
        "**Runtime > Change runtime type > Hardware accelerator > GPU > GPU type > T4**.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "5YP62vWc1w7s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rVnQg_Gixaj-"
      },
      "outputs": [],
      "source": [
        "# Caso esteja no Google Colab será necessário instalar apenas as dependências abaixo\n",
        "!pip install seqeval>=1.2.2\n",
        "!pip install evaluate>=0.4.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importando dataset\n",
        "\n",
        "Utilizaremos o dataset Rotten Tomatoes, que contém avaliações de filmes (https://huggingface.co/datasets/cornell-movie-review-data/rotten_tomatoes)."
      ],
      "metadata": {
        "id": "_snCPoeF6A0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Preparando dados\n",
        "tomatoes = load_dataset(\"rotten_tomatoes\")\n",
        "# Separando\n",
        "train_data, test_data = tomatoes[\"train\"], tomatoes[\"test\"]"
      ],
      "metadata": {
        "id": "5OZqDZZW6Bam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vejamos o que tem aqui...\n",
        "print(train_data)\n",
        "\n",
        "print(train_data[:10])\n",
        "\n",
        "print(train_data[-10:])"
      ],
      "metadata": {
        "id": "kODVhpi-ppnO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c489d4d-22b6-42dd-e156-4e347290e910"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['text', 'label'],\n",
            "    num_rows: 8530\n",
            "})\n",
            "{'text': ['the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .', 'the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson\\'s expanded vision of j . r . r . tolkien\\'s middle-earth .', 'effective but too-tepid biopic', 'if you sometimes like to go to the movies to have fun , wasabi is a good place to start .', \"emerges as something rare , an issue movie that's so honest and keenly observed that it doesn't feel like one .\", 'the film provides some great insight into the neurotic mindset of all comics -- even those who have reached the absolute top of the game .', 'offers that rare combination of entertainment and education .', 'perhaps no picture ever made has more literally showed that the road to hell is paved with good intentions .', \"steers turns in a snappy screenplay that curls at the edges ; it's so clever you want to hate it . but he somehow pulls it off .\", 'take care of my cat offers a refreshingly different slice of asian cinema .'], 'label': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "{'text': ['the star who helped give a spark to \" chasing amy \" and \" changing lanes \" falls flat as thinking man cia agent jack ryan in this summer\\'s new action film , \" the sum of all fears . \"', \"a summary of the plot doesn't quite do justice to the awfulness of the movie , for that comes through all too painfully in the execution .\", 'every conceivable mistake a director could make in filming opera has been perpetrated here .', \"snoots will no doubt rally to its cause , trotting out threadbare standbys like 'masterpiece' and 'triumph' and all that malarkey , but rarely does an established filmmaker so ardently waste viewers' time with a gobbler like this .\", '[the film\\'s] taste for \" shock humor \" will wear thin on all but those weaned on the comedy of tom green and the farrelly brothers .', 'any enjoyment will be hinge from a personal threshold of watching sad but endearing characters do extremely unconventional things .', \"if legendary shlockmeister ed wood had ever made a movie about a vampire , it probably would look a lot like this alarming production , adapted from anne rice's novel the vampire chronicles .\", \"hardly a nuanced portrait of a young woman's breakdown , the film nevertheless works up a few scares .\", 'interminably bleak , to say nothing of boring .', 'things really get weird , though not particularly scary : the movie is all portent and no content .'], 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carregando o modelo BERT\n",
        "\n",
        "Utilizaremos checkpoint \"bert-base-uncased\".\n",
        "\n",
        "Carregaremos o tokenizer, conforme exercícios anteriores, mas também a classe `AutoModelForSequenceClassification`.\n",
        "\n",
        "A classe `AutoModelForSequenceClassification` da biblioteca Hugging Face Transformers é uma classe automática projetada para simplificar o carregamento de modelos de Sequence Classification (Classificação de Sequência) já criando nossa Task Head.\n",
        "\n",
        "Vejamos a diferença entre o carregamento do modelo original e o modelo com a Task Head Classification."
      ],
      "metadata": {
        "id": "oEsGaF3O6Cm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoModelForSequenceClassification, AutoConfig\n",
        "import torch.nn as nn\n",
        "\n",
        "# Suprime warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# O checkpoint base do BERT (sem ajuste fino para tarefa específica)\n",
        "MODEL_CHECKPOINT = \"bert-base-uncased\"\n",
        "QNT_CLASSES = 2  # Definimos 2 classes (ex: positivo, negativo)\n",
        "\n",
        "print(\"--- 1. Carregando APENAS o Backbone BERT (BertModel) ---\")\n",
        "# AutoModel carrega o modelo base (o 'backbone' ou 'corpo' do transformer)\n",
        "modelo_base = AutoModel.from_pretrained(MODEL_CHECKPOINT)\n",
        "\n",
        "# Exibe a estrutura do modelo base\n",
        "print(modelo_base)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "print(f\"--- 2. Carregando BERT com a Cabeça de Classificação ({QNT_CLASSES} classes) ---\")\n",
        "\n",
        "# 2.1. Criar uma configuração para 2 classes\n",
        "config = AutoConfig.from_pretrained(MODEL_CHECKPOINT, num_labels=QNT_CLASSES)\n",
        "\n",
        "# 2.2. Carregar o modelo usando AutoModelForSequenceClassification\n",
        "modelo_class = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_CHECKPOINT,\n",
        "    config=config\n",
        ")\n",
        "\n",
        "# Exibe a estrutura do modelo de Classificação\n",
        "print(modelo_class)"
      ],
      "metadata": {
        "id": "TGrpxX_ohyAE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6c871f7e23d34bce8536de995601b4dc",
            "8216a2e792fd48bfb0822cb93e7a7eb1",
            "7af0a1bb6b6142d090ddee3386b749d8",
            "f8162356409f43db90197e39f44a9f07",
            "fe5ea8e98b6647919b1c2455e376d7b9",
            "73db6d718a9444d2bd3bcb64e9827ba0",
            "044070c9f93b4fb18dd86b701e1e8c29",
            "b6ea84f049074dc88ea034fa3dee95c6",
            "95f9a5c4356a4555a245249ec0a1e471",
            "8ff02fbc3a4f404da7bab42fcca83de8",
            "bb1b6c450a9b4332ae8d5617bfc5bde0",
            "1af1585eeef447f8b5cbd5bcead51b07",
            "4789a855406945b696814b208d90d183",
            "9c423de6b74f4588a0cf215c49cfdfe7",
            "2bee7807e617460f999676f744b949da",
            "2739a2ca2b2b4eb2a00d32a200af2b8d",
            "65e2ddc01fc3410e9be2d106ae517a6d",
            "da1dc0ea92a645c187231b122dd701f4",
            "45ff2c5531d04462ad87dae30b67ed68",
            "2a338569e4e344a6b35590873ee56dc3",
            "d33dc9047a17420db6626d5e8e8c7bf2",
            "d4dcebcac17d45f78a1ee75d3a9f35bb"
          ]
        },
        "outputId": "65d2418e-84de-4550-c1f1-e75b9a1de704"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. Carregando APENAS o Backbone BERT (BertModel) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c871f7e23d34bce8536de995601b4dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1af1585eeef447f8b5cbd5bcead51b07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertModel(\n",
            "  (embeddings): BertEmbeddings(\n",
            "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 768)\n",
            "    (token_type_embeddings): Embedding(2, 768)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): BertEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0-11): 12 x BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSdpaSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): BertPooler(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n",
            "\n",
            "================================================================================\n",
            "\n",
            "--- 2. Carregando BERT com a Cabeça de Classificação (2 classes) ---\n",
            "BertForSequenceClassification(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSdpaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregando novamente o modelo para utilização em nossa prática"
      ],
      "metadata": {
        "id": "p9xHaCz9ryXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "modelo = AutoModelForSequenceClassification.from_pretrained(MODEL_CHECKPOINT, num_labels=2)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)"
      ],
      "metadata": {
        "id": "4AUBQ0rfaeuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 💭 Tokenizando a entrada"
      ],
      "metadata": {
        "id": "ZN86ciIPafax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "# Necessário para otimizar o padding no batch\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Definindo função de preprocessamento dos dados\n",
        "def preprocessamento(itens):\n",
        "   return tokenizer(itens[\"text\"], truncation=True)\n",
        "\n",
        "# Tokenizando dados train e test\n",
        "tokenized_train = train_data.map(preprocessamento, batched=True)\n",
        "tokenized_test = test_data.map(preprocessamento, batched=True)"
      ],
      "metadata": {
        "id": "-RTfo1glfqFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definição de métricas"
      ],
      "metadata": {
        "id": "LVFBZrjMfqip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Calculate F1 score\"\"\"\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    load_f1 = evaluate.load(\"f1\")\n",
        "    f1 = load_f1.compute(predictions=predictions, references=labels)[\"f1\"]\n",
        "    return {\"f1\": f1}"
      ],
      "metadata": {
        "id": "01YCr_HbfsF7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinamento"
      ],
      "metadata": {
        "id": "42LzS7V8f_dm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "# Argumentos do treinamento\n",
        "training_args = TrainingArguments(\n",
        "   \"model\",\n",
        "   learning_rate=2e-5,\n",
        "   per_device_train_batch_size=16,\n",
        "   per_device_eval_batch_size=16,\n",
        "   num_train_epochs=1,\n",
        "   weight_decay=0.01,\n",
        "   save_strategy=\"epoch\",\n",
        "   report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Instanciando o objeto \"treinador\"\n",
        "treinador = Trainer(\n",
        "   model=modelo,\n",
        "   args=training_args,\n",
        "   train_dataset=tokenized_train,\n",
        "   eval_dataset=tokenized_test,\n",
        "   tokenizer=tokenizer,\n",
        "   data_collator=data_collator,\n",
        "   compute_metrics=compute_metrics,\n",
        ")\n"
      ],
      "metadata": {
        "id": "8dLXjLSsf_zI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treinador.train()"
      ],
      "metadata": {
        "id": "x7KEcV4_kzpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliando os resultados obtidos"
      ],
      "metadata": {
        "id": "9i0zYOdWgJy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "treinador.evaluate()"
      ],
      "metadata": {
        "id": "u-vfmXvogKF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ...mas o que foi treinado afinal de contas?\n",
        "\n",
        "Vamos exibir a configuração dos parâmetros para entender o que está acontecendo."
      ],
      "metadata": {
        "id": "MDZEaJF3uLOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibindo detalhes das camadas\n",
        "for name, param in modelo.named_parameters():\n",
        "    print(f\"Parameter: {name} ----- {param.requires_grad}\")"
      ],
      "metadata": {
        "id": "DTmXhL_qGL7t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a4922c2-dcf6-4115-895c-27a8275ab918"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter: bert.embeddings.word_embeddings.weight ----- True\n",
            "Parameter: bert.embeddings.position_embeddings.weight ----- True\n",
            "Parameter: bert.embeddings.token_type_embeddings.weight ----- True\n",
            "Parameter: bert.embeddings.LayerNorm.weight ----- True\n",
            "Parameter: bert.embeddings.LayerNorm.bias ----- True\n",
            "Parameter: bert.encoder.layer.0.attention.self.query.weight ----- True\n",
            "Parameter: bert.encoder.layer.0.attention.self.query.bias ----- True\n",
            "Parameter: bert.encoder.layer.0.attention.self.key.weight ----- True\n",
            "Parameter: bert.encoder.layer.0.attention.self.key.bias ----- True\n",
            "Parameter: bert.encoder.layer.0.attention.self.value.weight ----- True\n",
            "Parameter: bert.encoder.layer.0.attention.self.value.bias ----- True\n",
            "Parameter: bert.encoder.layer.0.attention.output.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.0.attention.output.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.0.attention.output.LayerNorm.weight ----- True\n",
            "Parameter: bert.encoder.layer.0.attention.output.LayerNorm.bias ----- True\n",
            "Parameter: bert.encoder.layer.0.intermediate.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.0.intermediate.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.0.output.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.0.output.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.0.output.LayerNorm.weight ----- True\n",
            "Parameter: bert.encoder.layer.0.output.LayerNorm.bias ----- True\n",
            "Parameter: bert.encoder.layer.1.attention.self.query.weight ----- True\n",
            "Parameter: bert.encoder.layer.1.attention.self.query.bias ----- True\n",
            "Parameter: bert.encoder.layer.1.attention.self.key.weight ----- True\n",
            "Parameter: bert.encoder.layer.1.attention.self.key.bias ----- True\n",
            "Parameter: bert.encoder.layer.1.attention.self.value.weight ----- True\n",
            "Parameter: bert.encoder.layer.1.attention.self.value.bias ----- True\n",
            "Parameter: bert.encoder.layer.1.attention.output.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.1.attention.output.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.1.attention.output.LayerNorm.weight ----- True\n",
            "Parameter: bert.encoder.layer.1.attention.output.LayerNorm.bias ----- True\n",
            "Parameter: bert.encoder.layer.1.intermediate.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.1.intermediate.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.1.output.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.1.output.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.1.output.LayerNorm.weight ----- True\n",
            "Parameter: bert.encoder.layer.1.output.LayerNorm.bias ----- True\n",
            "Parameter: bert.encoder.layer.2.attention.self.query.weight ----- True\n",
            "Parameter: bert.encoder.layer.2.attention.self.query.bias ----- True\n",
            "Parameter: bert.encoder.layer.2.attention.self.key.weight ----- True\n",
            "Parameter: bert.encoder.layer.2.attention.self.key.bias ----- True\n",
            "Parameter: bert.encoder.layer.2.attention.self.value.weight ----- True\n",
            "Parameter: bert.encoder.layer.2.attention.self.value.bias ----- True\n",
            "Parameter: bert.encoder.layer.2.attention.output.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.2.attention.output.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.2.attention.output.LayerNorm.weight ----- True\n",
            "Parameter: bert.encoder.layer.2.attention.output.LayerNorm.bias ----- True\n",
            "Parameter: bert.encoder.layer.2.intermediate.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.2.intermediate.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.2.output.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.2.output.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.2.output.LayerNorm.weight ----- True\n",
            "Parameter: bert.encoder.layer.2.output.LayerNorm.bias ----- True\n",
            "Parameter: bert.encoder.layer.3.attention.self.query.weight ----- True\n",
            "Parameter: bert.encoder.layer.3.attention.self.query.bias ----- True\n",
            "Parameter: bert.encoder.layer.3.attention.self.key.weight ----- True\n",
            "Parameter: bert.encoder.layer.3.attention.self.key.bias ----- True\n",
            "Parameter: bert.encoder.layer.3.attention.self.value.weight ----- True\n",
            "Parameter: bert.encoder.layer.3.attention.self.value.bias ----- True\n",
            "Parameter: bert.encoder.layer.3.attention.output.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.3.attention.output.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.3.attention.output.LayerNorm.weight ----- True\n",
            "Parameter: bert.encoder.layer.3.attention.output.LayerNorm.bias ----- True\n",
            "Parameter: bert.encoder.layer.3.intermediate.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.3.intermediate.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.3.output.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.3.output.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.3.output.LayerNorm.weight ----- True\n",
            "Parameter: bert.encoder.layer.3.output.LayerNorm.bias ----- True\n",
            "Parameter: bert.encoder.layer.4.attention.self.query.weight ----- True\n",
            "Parameter: bert.encoder.layer.4.attention.self.query.bias ----- True\n",
            "Parameter: bert.encoder.layer.4.attention.self.key.weight ----- True\n",
            "Parameter: bert.encoder.layer.4.attention.self.key.bias ----- True\n",
            "Parameter: bert.encoder.layer.4.attention.self.value.weight ----- True\n",
            "Parameter: bert.encoder.layer.4.attention.self.value.bias ----- True\n",
            "Parameter: bert.encoder.layer.4.attention.output.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.4.attention.output.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.4.attention.output.LayerNorm.weight ----- True\n",
            "Parameter: bert.encoder.layer.4.attention.output.LayerNorm.bias ----- True\n",
            "Parameter: bert.encoder.layer.4.intermediate.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.4.intermediate.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.4.output.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.4.output.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.4.output.LayerNorm.weight ----- True\n",
            "Parameter: bert.encoder.layer.4.output.LayerNorm.bias ----- True\n",
            "Parameter: bert.encoder.layer.5.attention.self.query.weight ----- True\n",
            "Parameter: bert.encoder.layer.5.attention.self.query.bias ----- True\n",
            "Parameter: bert.encoder.layer.5.attention.self.key.weight ----- True\n",
            "Parameter: bert.encoder.layer.5.attention.self.key.bias ----- True\n",
            "Parameter: bert.encoder.layer.5.attention.self.value.weight ----- True\n",
            "Parameter: bert.encoder.layer.5.attention.self.value.bias ----- True\n",
            "Parameter: bert.encoder.layer.5.attention.output.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.5.attention.output.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.5.attention.output.LayerNorm.weight ----- True\n",
            "Parameter: bert.encoder.layer.5.attention.output.LayerNorm.bias ----- True\n",
            "Parameter: bert.encoder.layer.5.intermediate.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.5.intermediate.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.5.output.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.5.output.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.5.output.LayerNorm.weight ----- True\n",
            "Parameter: bert.encoder.layer.5.output.LayerNorm.bias ----- True\n",
            "Parameter: bert.encoder.layer.6.attention.self.query.weight ----- True\n",
            "Parameter: bert.encoder.layer.6.attention.self.query.bias ----- True\n",
            "Parameter: bert.encoder.layer.6.attention.self.key.weight ----- True\n",
            "Parameter: bert.encoder.layer.6.attention.self.key.bias ----- True\n",
            "Parameter: bert.encoder.layer.6.attention.self.value.weight ----- True\n",
            "Parameter: bert.encoder.layer.6.attention.self.value.bias ----- True\n",
            "Parameter: bert.encoder.layer.6.attention.output.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.6.attention.output.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.6.attention.output.LayerNorm.weight ----- True\n",
            "Parameter: bert.encoder.layer.6.attention.output.LayerNorm.bias ----- True\n",
            "Parameter: bert.encoder.layer.6.intermediate.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.6.intermediate.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.6.output.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.6.output.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.6.output.LayerNorm.weight ----- True\n",
            "Parameter: bert.encoder.layer.6.output.LayerNorm.bias ----- True\n",
            "Parameter: bert.encoder.layer.7.attention.self.query.weight ----- True\n",
            "Parameter: bert.encoder.layer.7.attention.self.query.bias ----- True\n",
            "Parameter: bert.encoder.layer.7.attention.self.key.weight ----- True\n",
            "Parameter: bert.encoder.layer.7.attention.self.key.bias ----- True\n",
            "Parameter: bert.encoder.layer.7.attention.self.value.weight ----- True\n",
            "Parameter: bert.encoder.layer.7.attention.self.value.bias ----- True\n",
            "Parameter: bert.encoder.layer.7.attention.output.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.7.attention.output.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.7.attention.output.LayerNorm.weight ----- True\n",
            "Parameter: bert.encoder.layer.7.attention.output.LayerNorm.bias ----- True\n",
            "Parameter: bert.encoder.layer.7.intermediate.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.7.intermediate.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.7.output.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.7.output.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.7.output.LayerNorm.weight ----- True\n",
            "Parameter: bert.encoder.layer.7.output.LayerNorm.bias ----- True\n",
            "Parameter: bert.encoder.layer.8.attention.self.query.weight ----- True\n",
            "Parameter: bert.encoder.layer.8.attention.self.query.bias ----- True\n",
            "Parameter: bert.encoder.layer.8.attention.self.key.weight ----- True\n",
            "Parameter: bert.encoder.layer.8.attention.self.key.bias ----- True\n",
            "Parameter: bert.encoder.layer.8.attention.self.value.weight ----- True\n",
            "Parameter: bert.encoder.layer.8.attention.self.value.bias ----- True\n",
            "Parameter: bert.encoder.layer.8.attention.output.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.8.attention.output.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.8.attention.output.LayerNorm.weight ----- True\n",
            "Parameter: bert.encoder.layer.8.attention.output.LayerNorm.bias ----- True\n",
            "Parameter: bert.encoder.layer.8.intermediate.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.8.intermediate.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.8.output.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.8.output.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.8.output.LayerNorm.weight ----- True\n",
            "Parameter: bert.encoder.layer.8.output.LayerNorm.bias ----- True\n",
            "Parameter: bert.encoder.layer.9.attention.self.query.weight ----- True\n",
            "Parameter: bert.encoder.layer.9.attention.self.query.bias ----- True\n",
            "Parameter: bert.encoder.layer.9.attention.self.key.weight ----- True\n",
            "Parameter: bert.encoder.layer.9.attention.self.key.bias ----- True\n",
            "Parameter: bert.encoder.layer.9.attention.self.value.weight ----- True\n",
            "Parameter: bert.encoder.layer.9.attention.self.value.bias ----- True\n",
            "Parameter: bert.encoder.layer.9.attention.output.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.9.attention.output.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.9.attention.output.LayerNorm.weight ----- True\n",
            "Parameter: bert.encoder.layer.9.attention.output.LayerNorm.bias ----- True\n",
            "Parameter: bert.encoder.layer.9.intermediate.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.9.intermediate.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.9.output.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.9.output.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.9.output.LayerNorm.weight ----- True\n",
            "Parameter: bert.encoder.layer.9.output.LayerNorm.bias ----- True\n",
            "Parameter: bert.encoder.layer.10.attention.self.query.weight ----- True\n",
            "Parameter: bert.encoder.layer.10.attention.self.query.bias ----- True\n",
            "Parameter: bert.encoder.layer.10.attention.self.key.weight ----- True\n",
            "Parameter: bert.encoder.layer.10.attention.self.key.bias ----- True\n",
            "Parameter: bert.encoder.layer.10.attention.self.value.weight ----- True\n",
            "Parameter: bert.encoder.layer.10.attention.self.value.bias ----- True\n",
            "Parameter: bert.encoder.layer.10.attention.output.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.10.attention.output.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.10.attention.output.LayerNorm.weight ----- True\n",
            "Parameter: bert.encoder.layer.10.attention.output.LayerNorm.bias ----- True\n",
            "Parameter: bert.encoder.layer.10.intermediate.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.10.intermediate.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.10.output.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.10.output.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.10.output.LayerNorm.weight ----- True\n",
            "Parameter: bert.encoder.layer.10.output.LayerNorm.bias ----- True\n",
            "Parameter: bert.encoder.layer.11.attention.self.query.weight ----- True\n",
            "Parameter: bert.encoder.layer.11.attention.self.query.bias ----- True\n",
            "Parameter: bert.encoder.layer.11.attention.self.key.weight ----- True\n",
            "Parameter: bert.encoder.layer.11.attention.self.key.bias ----- True\n",
            "Parameter: bert.encoder.layer.11.attention.self.value.weight ----- True\n",
            "Parameter: bert.encoder.layer.11.attention.self.value.bias ----- True\n",
            "Parameter: bert.encoder.layer.11.attention.output.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.11.attention.output.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.11.attention.output.LayerNorm.weight ----- True\n",
            "Parameter: bert.encoder.layer.11.attention.output.LayerNorm.bias ----- True\n",
            "Parameter: bert.encoder.layer.11.intermediate.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.11.intermediate.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.11.output.dense.weight ----- True\n",
            "Parameter: bert.encoder.layer.11.output.dense.bias ----- True\n",
            "Parameter: bert.encoder.layer.11.output.LayerNorm.weight ----- True\n",
            "Parameter: bert.encoder.layer.11.output.LayerNorm.bias ----- True\n",
            "Parameter: bert.pooler.dense.weight ----- True\n",
            "Parameter: bert.pooler.dense.bias ----- True\n",
            "Parameter: classifier.weight ----- True\n",
            "Parameter: classifier.bias ----- True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⛄ 🥶 🧊❄ Congelamento de Camadas 🧊🧊🧊 ☃ ❄ 🥶\n",
        "\n",
        "Uma tática muito comum para fine tuning é o congelamento de camadas, ou seja, bloquear a atualização dos pesos no treinamento da rede neural.\n",
        "\n",
        "O 🐍PyTorch🔥 permite configurar explicitamente quais parâmetros podem ser atualizados. O atributo `requires_grad` é um boolean que controla se o parâmetro requer cálculo de gradiente. Ou seja, quando `requires_grad == False` o sistema de autograd do PyTorch não rastreia as operações que o envolvem, não calcula nem armazena seu gradiente durante o backpropagation, e, consequentemente, o otimizador não ajusta seu valor, mantendo-o constante ao longo de todo o processo de treinamento.\n",
        "\n",
        "---\n",
        "\n",
        "Vamos carregar novamente o modelo, mas agora vamos ajustar essa flag apenas nos parâmetros da camada de classificação.\n",
        "\n"
      ],
      "metadata": {
        "id": "Gevk9yXSgx4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model and Tokenizer\n",
        "modelo_bert_congelado = AutoModelForSequenceClassification.from_pretrained(MODEL_CHECKPOINT, num_labels=2)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
        "\n",
        "for name, param in modelo_bert_congelado.named_parameters():\n",
        "    # Ajusta a camada \"classifier\"\n",
        "    if name.startswith(\"classifier\"):\n",
        "      param.requires_grad = True\n",
        "    else:\n",
        "      param.requires_grad = False\n",
        "    print(f\"Parameter: {name} ----- {param.requires_grad}\")"
      ],
      "metadata": {
        "id": "PySQO8z9GMyr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b748c216-aefa-463b-efb7-49122f6a0a67"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter: bert.embeddings.word_embeddings.weight ----- False\n",
            "Parameter: bert.embeddings.position_embeddings.weight ----- False\n",
            "Parameter: bert.embeddings.token_type_embeddings.weight ----- False\n",
            "Parameter: bert.embeddings.LayerNorm.weight ----- False\n",
            "Parameter: bert.embeddings.LayerNorm.bias ----- False\n",
            "Parameter: bert.encoder.layer.0.attention.self.query.weight ----- False\n",
            "Parameter: bert.encoder.layer.0.attention.self.query.bias ----- False\n",
            "Parameter: bert.encoder.layer.0.attention.self.key.weight ----- False\n",
            "Parameter: bert.encoder.layer.0.attention.self.key.bias ----- False\n",
            "Parameter: bert.encoder.layer.0.attention.self.value.weight ----- False\n",
            "Parameter: bert.encoder.layer.0.attention.self.value.bias ----- False\n",
            "Parameter: bert.encoder.layer.0.attention.output.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.0.attention.output.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.0.attention.output.LayerNorm.weight ----- False\n",
            "Parameter: bert.encoder.layer.0.attention.output.LayerNorm.bias ----- False\n",
            "Parameter: bert.encoder.layer.0.intermediate.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.0.intermediate.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.0.output.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.0.output.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.0.output.LayerNorm.weight ----- False\n",
            "Parameter: bert.encoder.layer.0.output.LayerNorm.bias ----- False\n",
            "Parameter: bert.encoder.layer.1.attention.self.query.weight ----- False\n",
            "Parameter: bert.encoder.layer.1.attention.self.query.bias ----- False\n",
            "Parameter: bert.encoder.layer.1.attention.self.key.weight ----- False\n",
            "Parameter: bert.encoder.layer.1.attention.self.key.bias ----- False\n",
            "Parameter: bert.encoder.layer.1.attention.self.value.weight ----- False\n",
            "Parameter: bert.encoder.layer.1.attention.self.value.bias ----- False\n",
            "Parameter: bert.encoder.layer.1.attention.output.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.1.attention.output.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.1.attention.output.LayerNorm.weight ----- False\n",
            "Parameter: bert.encoder.layer.1.attention.output.LayerNorm.bias ----- False\n",
            "Parameter: bert.encoder.layer.1.intermediate.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.1.intermediate.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.1.output.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.1.output.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.1.output.LayerNorm.weight ----- False\n",
            "Parameter: bert.encoder.layer.1.output.LayerNorm.bias ----- False\n",
            "Parameter: bert.encoder.layer.2.attention.self.query.weight ----- False\n",
            "Parameter: bert.encoder.layer.2.attention.self.query.bias ----- False\n",
            "Parameter: bert.encoder.layer.2.attention.self.key.weight ----- False\n",
            "Parameter: bert.encoder.layer.2.attention.self.key.bias ----- False\n",
            "Parameter: bert.encoder.layer.2.attention.self.value.weight ----- False\n",
            "Parameter: bert.encoder.layer.2.attention.self.value.bias ----- False\n",
            "Parameter: bert.encoder.layer.2.attention.output.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.2.attention.output.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.2.attention.output.LayerNorm.weight ----- False\n",
            "Parameter: bert.encoder.layer.2.attention.output.LayerNorm.bias ----- False\n",
            "Parameter: bert.encoder.layer.2.intermediate.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.2.intermediate.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.2.output.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.2.output.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.2.output.LayerNorm.weight ----- False\n",
            "Parameter: bert.encoder.layer.2.output.LayerNorm.bias ----- False\n",
            "Parameter: bert.encoder.layer.3.attention.self.query.weight ----- False\n",
            "Parameter: bert.encoder.layer.3.attention.self.query.bias ----- False\n",
            "Parameter: bert.encoder.layer.3.attention.self.key.weight ----- False\n",
            "Parameter: bert.encoder.layer.3.attention.self.key.bias ----- False\n",
            "Parameter: bert.encoder.layer.3.attention.self.value.weight ----- False\n",
            "Parameter: bert.encoder.layer.3.attention.self.value.bias ----- False\n",
            "Parameter: bert.encoder.layer.3.attention.output.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.3.attention.output.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.3.attention.output.LayerNorm.weight ----- False\n",
            "Parameter: bert.encoder.layer.3.attention.output.LayerNorm.bias ----- False\n",
            "Parameter: bert.encoder.layer.3.intermediate.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.3.intermediate.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.3.output.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.3.output.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.3.output.LayerNorm.weight ----- False\n",
            "Parameter: bert.encoder.layer.3.output.LayerNorm.bias ----- False\n",
            "Parameter: bert.encoder.layer.4.attention.self.query.weight ----- False\n",
            "Parameter: bert.encoder.layer.4.attention.self.query.bias ----- False\n",
            "Parameter: bert.encoder.layer.4.attention.self.key.weight ----- False\n",
            "Parameter: bert.encoder.layer.4.attention.self.key.bias ----- False\n",
            "Parameter: bert.encoder.layer.4.attention.self.value.weight ----- False\n",
            "Parameter: bert.encoder.layer.4.attention.self.value.bias ----- False\n",
            "Parameter: bert.encoder.layer.4.attention.output.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.4.attention.output.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.4.attention.output.LayerNorm.weight ----- False\n",
            "Parameter: bert.encoder.layer.4.attention.output.LayerNorm.bias ----- False\n",
            "Parameter: bert.encoder.layer.4.intermediate.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.4.intermediate.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.4.output.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.4.output.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.4.output.LayerNorm.weight ----- False\n",
            "Parameter: bert.encoder.layer.4.output.LayerNorm.bias ----- False\n",
            "Parameter: bert.encoder.layer.5.attention.self.query.weight ----- False\n",
            "Parameter: bert.encoder.layer.5.attention.self.query.bias ----- False\n",
            "Parameter: bert.encoder.layer.5.attention.self.key.weight ----- False\n",
            "Parameter: bert.encoder.layer.5.attention.self.key.bias ----- False\n",
            "Parameter: bert.encoder.layer.5.attention.self.value.weight ----- False\n",
            "Parameter: bert.encoder.layer.5.attention.self.value.bias ----- False\n",
            "Parameter: bert.encoder.layer.5.attention.output.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.5.attention.output.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.5.attention.output.LayerNorm.weight ----- False\n",
            "Parameter: bert.encoder.layer.5.attention.output.LayerNorm.bias ----- False\n",
            "Parameter: bert.encoder.layer.5.intermediate.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.5.intermediate.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.5.output.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.5.output.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.5.output.LayerNorm.weight ----- False\n",
            "Parameter: bert.encoder.layer.5.output.LayerNorm.bias ----- False\n",
            "Parameter: bert.encoder.layer.6.attention.self.query.weight ----- False\n",
            "Parameter: bert.encoder.layer.6.attention.self.query.bias ----- False\n",
            "Parameter: bert.encoder.layer.6.attention.self.key.weight ----- False\n",
            "Parameter: bert.encoder.layer.6.attention.self.key.bias ----- False\n",
            "Parameter: bert.encoder.layer.6.attention.self.value.weight ----- False\n",
            "Parameter: bert.encoder.layer.6.attention.self.value.bias ----- False\n",
            "Parameter: bert.encoder.layer.6.attention.output.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.6.attention.output.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.6.attention.output.LayerNorm.weight ----- False\n",
            "Parameter: bert.encoder.layer.6.attention.output.LayerNorm.bias ----- False\n",
            "Parameter: bert.encoder.layer.6.intermediate.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.6.intermediate.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.6.output.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.6.output.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.6.output.LayerNorm.weight ----- False\n",
            "Parameter: bert.encoder.layer.6.output.LayerNorm.bias ----- False\n",
            "Parameter: bert.encoder.layer.7.attention.self.query.weight ----- False\n",
            "Parameter: bert.encoder.layer.7.attention.self.query.bias ----- False\n",
            "Parameter: bert.encoder.layer.7.attention.self.key.weight ----- False\n",
            "Parameter: bert.encoder.layer.7.attention.self.key.bias ----- False\n",
            "Parameter: bert.encoder.layer.7.attention.self.value.weight ----- False\n",
            "Parameter: bert.encoder.layer.7.attention.self.value.bias ----- False\n",
            "Parameter: bert.encoder.layer.7.attention.output.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.7.attention.output.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.7.attention.output.LayerNorm.weight ----- False\n",
            "Parameter: bert.encoder.layer.7.attention.output.LayerNorm.bias ----- False\n",
            "Parameter: bert.encoder.layer.7.intermediate.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.7.intermediate.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.7.output.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.7.output.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.7.output.LayerNorm.weight ----- False\n",
            "Parameter: bert.encoder.layer.7.output.LayerNorm.bias ----- False\n",
            "Parameter: bert.encoder.layer.8.attention.self.query.weight ----- False\n",
            "Parameter: bert.encoder.layer.8.attention.self.query.bias ----- False\n",
            "Parameter: bert.encoder.layer.8.attention.self.key.weight ----- False\n",
            "Parameter: bert.encoder.layer.8.attention.self.key.bias ----- False\n",
            "Parameter: bert.encoder.layer.8.attention.self.value.weight ----- False\n",
            "Parameter: bert.encoder.layer.8.attention.self.value.bias ----- False\n",
            "Parameter: bert.encoder.layer.8.attention.output.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.8.attention.output.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.8.attention.output.LayerNorm.weight ----- False\n",
            "Parameter: bert.encoder.layer.8.attention.output.LayerNorm.bias ----- False\n",
            "Parameter: bert.encoder.layer.8.intermediate.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.8.intermediate.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.8.output.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.8.output.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.8.output.LayerNorm.weight ----- False\n",
            "Parameter: bert.encoder.layer.8.output.LayerNorm.bias ----- False\n",
            "Parameter: bert.encoder.layer.9.attention.self.query.weight ----- False\n",
            "Parameter: bert.encoder.layer.9.attention.self.query.bias ----- False\n",
            "Parameter: bert.encoder.layer.9.attention.self.key.weight ----- False\n",
            "Parameter: bert.encoder.layer.9.attention.self.key.bias ----- False\n",
            "Parameter: bert.encoder.layer.9.attention.self.value.weight ----- False\n",
            "Parameter: bert.encoder.layer.9.attention.self.value.bias ----- False\n",
            "Parameter: bert.encoder.layer.9.attention.output.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.9.attention.output.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.9.attention.output.LayerNorm.weight ----- False\n",
            "Parameter: bert.encoder.layer.9.attention.output.LayerNorm.bias ----- False\n",
            "Parameter: bert.encoder.layer.9.intermediate.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.9.intermediate.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.9.output.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.9.output.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.9.output.LayerNorm.weight ----- False\n",
            "Parameter: bert.encoder.layer.9.output.LayerNorm.bias ----- False\n",
            "Parameter: bert.encoder.layer.10.attention.self.query.weight ----- False\n",
            "Parameter: bert.encoder.layer.10.attention.self.query.bias ----- False\n",
            "Parameter: bert.encoder.layer.10.attention.self.key.weight ----- False\n",
            "Parameter: bert.encoder.layer.10.attention.self.key.bias ----- False\n",
            "Parameter: bert.encoder.layer.10.attention.self.value.weight ----- False\n",
            "Parameter: bert.encoder.layer.10.attention.self.value.bias ----- False\n",
            "Parameter: bert.encoder.layer.10.attention.output.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.10.attention.output.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.10.attention.output.LayerNorm.weight ----- False\n",
            "Parameter: bert.encoder.layer.10.attention.output.LayerNorm.bias ----- False\n",
            "Parameter: bert.encoder.layer.10.intermediate.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.10.intermediate.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.10.output.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.10.output.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.10.output.LayerNorm.weight ----- False\n",
            "Parameter: bert.encoder.layer.10.output.LayerNorm.bias ----- False\n",
            "Parameter: bert.encoder.layer.11.attention.self.query.weight ----- False\n",
            "Parameter: bert.encoder.layer.11.attention.self.query.bias ----- False\n",
            "Parameter: bert.encoder.layer.11.attention.self.key.weight ----- False\n",
            "Parameter: bert.encoder.layer.11.attention.self.key.bias ----- False\n",
            "Parameter: bert.encoder.layer.11.attention.self.value.weight ----- False\n",
            "Parameter: bert.encoder.layer.11.attention.self.value.bias ----- False\n",
            "Parameter: bert.encoder.layer.11.attention.output.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.11.attention.output.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.11.attention.output.LayerNorm.weight ----- False\n",
            "Parameter: bert.encoder.layer.11.attention.output.LayerNorm.bias ----- False\n",
            "Parameter: bert.encoder.layer.11.intermediate.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.11.intermediate.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.11.output.dense.weight ----- False\n",
            "Parameter: bert.encoder.layer.11.output.dense.bias ----- False\n",
            "Parameter: bert.encoder.layer.11.output.LayerNorm.weight ----- False\n",
            "Parameter: bert.encoder.layer.11.output.LayerNorm.bias ----- False\n",
            "Parameter: bert.pooler.dense.weight ----- False\n",
            "Parameter: bert.pooler.dense.bias ----- False\n",
            "Parameter: classifier.weight ----- True\n",
            "Parameter: classifier.bias ----- True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinando o modelo carregado novamente\n",
        "\n",
        "Agora será executado o processo de treinamento e vejamos a diferença."
      ],
      "metadata": {
        "id": "NiQ6G8suGMap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "treinador = Trainer(\n",
        "   model=modelo_bert_congelado,\n",
        "   args=training_args,\n",
        "   train_dataset=tokenized_train,\n",
        "   eval_dataset=tokenized_test,\n",
        "   tokenizer=tokenizer,\n",
        "   data_collator=data_collator,\n",
        "   compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "treinador.train()"
      ],
      "metadata": {
        "id": "2OnIna8_8Cqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nova Avaliação do treinamento 🏋"
      ],
      "metadata": {
        "id": "InGCasni8pPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "treinador.evaluate()"
      ],
      "metadata": {
        "id": "iBlR5GGo88-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5827afd1"
      },
      "source": [
        "from datasets import concatenate_datasets\n",
        "\n",
        "# Pegar exemplos do dataset de teste (mistura de positivos e negativos)\n",
        "positive_reviews = test_data.filter(lambda example: example['label'] == 1).select(range(5))\n",
        "negative_reviews = test_data.filter(lambda example: example['label'] == 0).select(range(5))\n",
        "\n",
        "# Combinar os exemplos\n",
        "sample_reviews = concatenate_datasets([positive_reviews, negative_reviews])\n",
        "\n",
        "\n",
        "# Preprocessar as avaliações individualmente\n",
        "tokenized_sample_list = [tokenizer(review, truncation=True) for review in sample_reviews['text']]\n",
        "\n",
        "# Usar o data collator para preparar a entrada para o modelo\n",
        "import torch\n",
        "batch = data_collator(tokenized_sample_list)\n",
        "\n",
        "# Mover o batch para o mesmo dispositivo do modelo\n",
        "batch = {k: v.to(modelo_bert_congelado.device) for k, v in batch.items()}\n",
        "\n",
        "\n",
        "# Fazer previsões\n",
        "with torch.no_grad():\n",
        "    outputs = modelo_bert_congelado(**batch)\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "# Exibir os resultados\n",
        "for i, review in enumerate(sample_reviews['text']):\n",
        "    predicted_label = \"Positive\" if predictions[i].item() == 1 else \"Negative\"\n",
        "    # label real para fins de comparação\n",
        "    actual_label = \"Positive\" if sample_reviews['label'][i] == 1 else \"Negative\"\n",
        "    print(f\"Review: {review}\\nPredicted Label: {predicted_label}\\nActual Label: {actual_label}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Para testar o classificador com uma string sua, utilize o código abaixo:\n",
        "\n",
        "Lembre-se de enviar a variável para a GPU, para não ver nenhum erro bizarro 😅."
      ],
      "metadata": {
        "id": "jiX8zI-IqzeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto_teste = \"This is a horrible movie\"\n",
        "\n",
        "# Executa inferência no modelo treinado\n",
        "# Mudando para o modo eval\n",
        "modelo.eval()\n",
        "\n",
        "entrada_tokenizada = tokenizer(texto_teste, return_tensors=\"pt\")\n",
        "\n",
        "# Move os tensores para o dispositivo em que o modelo se encontra\n",
        "device = modelo.device\n",
        "entrada_tokenizada = {k: v.to(device) for k, v in entrada_tokenizada.items()}\n",
        "\n",
        "with torch.no_grad():\n",
        "  saida = modelo_bert_congelado(**entrada_tokenizada)\n",
        "\n",
        "print(f\"Saída bruta: {saida}\")\n",
        "\n",
        "# Trabalhando a saída bruta\n",
        "logits = saida.logits\n",
        "\n",
        "prob = torch.softmax(logits, dim=1)\n",
        "print(f\"Probabilidades: {prob}\")"
      ],
      "metadata": {
        "id": "wO-rX4TZrAdK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b594d4cd-38bd-4460-8a62-1e8c580a9b29"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saída bruta: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.2159, -0.0121]], device='cuda:0'), hidden_states=None, attentions=None)\n",
            "Probabilidades: tensor([[0.5568, 0.4432]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "# Tarefas do Exercício\n",
        "## 1. Agora responda com suas palavras o que aconteceu em ambos os casos durante o treinamento, evidenciando se você percebeu alguma diferença durante o passo de treinamento. Discuta brevemente os resultados obtidos."
      ],
      "metadata": {
        "id": "jAi-YJhT9COa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# No segundo caso (modelo congelado), o treinamento é mais leve e estável, mas limitado, sendo eficiente quando o conjunto de dados é pequeno\n",
        "# ou quando a tarefa é semelhante ao que o BERT já sabe. No primeiro (modelo descongelado), o modelo aprende mais profundamente, o que normalmente\n",
        "# leva a desempenho superior, porém com maior custo de tempo e complexidade de treinamento."
      ],
      "metadata": {
        "id": "OmGcPqWj-KJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Conforme instruções anteriores, carregue mais uma vez o modelo BERT, mas agora mantenha apenas a partir da camada encoder 10 (`bert.encoder.layer.10`) do modelo BERT como treinável (`require_grad == True`). Ou seja, congele (`requires_grad == False`) até a camada encoder 9 (`bert.encoder.layer.9`)."
      ],
      "metadata": {
        "id": "pyBCsKgx-Rfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model and Tokenizer\n",
        "modelo_bert_congelado2 = AutoModelForSequenceClassification.from_pretrained(MODEL_CHECKPOINT, num_labels=2)\n",
        "tokenizer2 = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
        "\n",
        "# 1) Congelar TODAS as camadas inicialmente\n",
        "for param in modelo_bert_congelado2.bert.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 2) Descongelar a partir da camada 10 (10 e 11)\n",
        "for param in modelo_bert_congelado2.bert.encoder.layer[10:].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# (Opcional) também descongelar o pooler\n",
        "for param in modelo_bert_congelado2.bert.pooler.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# O classificador final já vem descongelado por padrão\n",
        "for param in modelo_bert_congelado2.classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "#testa se deu certo\n",
        "for name, param in modelo_bert_congelado2.named_parameters():\n",
        "  if \"encoder.layer.9\" in name:\n",
        "    print(name, \"->\", param.requires_grad)\n",
        "  if \"encoder.layer.10\" in name:\n",
        "    print(name, \"->\", param.requires_grad)"
      ],
      "metadata": {
        "id": "g2uLu1xb-SOP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00598503-e501-477b-b5a6-2e3c6dcf0ea8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert.encoder.layer.9.attention.self.query.weight -> False\n",
            "bert.encoder.layer.9.attention.self.query.bias -> False\n",
            "bert.encoder.layer.9.attention.self.key.weight -> False\n",
            "bert.encoder.layer.9.attention.self.key.bias -> False\n",
            "bert.encoder.layer.9.attention.self.value.weight -> False\n",
            "bert.encoder.layer.9.attention.self.value.bias -> False\n",
            "bert.encoder.layer.9.attention.output.dense.weight -> False\n",
            "bert.encoder.layer.9.attention.output.dense.bias -> False\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.weight -> False\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.bias -> False\n",
            "bert.encoder.layer.9.intermediate.dense.weight -> False\n",
            "bert.encoder.layer.9.intermediate.dense.bias -> False\n",
            "bert.encoder.layer.9.output.dense.weight -> False\n",
            "bert.encoder.layer.9.output.dense.bias -> False\n",
            "bert.encoder.layer.9.output.LayerNorm.weight -> False\n",
            "bert.encoder.layer.9.output.LayerNorm.bias -> False\n",
            "bert.encoder.layer.10.attention.self.query.weight -> True\n",
            "bert.encoder.layer.10.attention.self.query.bias -> True\n",
            "bert.encoder.layer.10.attention.self.key.weight -> True\n",
            "bert.encoder.layer.10.attention.self.key.bias -> True\n",
            "bert.encoder.layer.10.attention.self.value.weight -> True\n",
            "bert.encoder.layer.10.attention.self.value.bias -> True\n",
            "bert.encoder.layer.10.attention.output.dense.weight -> True\n",
            "bert.encoder.layer.10.attention.output.dense.bias -> True\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.weight -> True\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.bias -> True\n",
            "bert.encoder.layer.10.intermediate.dense.weight -> True\n",
            "bert.encoder.layer.10.intermediate.dense.bias -> True\n",
            "bert.encoder.layer.10.output.dense.weight -> True\n",
            "bert.encoder.layer.10.output.dense.bias -> True\n",
            "bert.encoder.layer.10.output.LayerNorm.weight -> True\n",
            "bert.encoder.layer.10.output.LayerNorm.bias -> True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Execute o treinamento com os mesmos parâmetros utilizados anteriormente e execute o método `evaluate()` para calcular as métricas e discuta os resultados obtidos.\n",
        "Caso julgar necessário, execute outros treinamentos ajustando quantidades distintas de parâmetros treináveis para tirar conclusões adicionais."
      ],
      "metadata": {
        "id": "eU2EwUJhDnyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "treinador = Trainer(\n",
        "   model=modelo_bert_congelado2,\n",
        "   args=training_args,\n",
        "   train_dataset=tokenized_train,\n",
        "   eval_dataset=tokenized_test,\n",
        "   tokenizer=tokenizer,\n",
        "   data_collator=data_collator,\n",
        "   compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "treinador.train()"
      ],
      "metadata": {
        "id": "OmJ0zHbTD56S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treinador.evaluate()"
      ],
      "metadata": {
        "id": "F60lHzIMdhWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. (BÔNUS) Pesquise e escolha outro dataset para fazer fine tuning do modelo BERT."
      ],
      "metadata": {
        "id": "U2Z0zXA49fcb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "#Dataset SST-2 (Stanford Sentiment Treebank 2)\n",
        "#Tarefa: Sentiment Analysis (positivo/negativo)\n",
        "#Tamanho: ~70k exemplos\n",
        "#Fonte: GLUE Benchmark\n",
        "#Domínio: Frases de reviews de filmes\n",
        "\n",
        "sst2 = load_dataset(\"glue\", \"sst2\")\n",
        "ds_train = sst2[\"train\"]        # ~67k\n",
        "ds_valid = sst2[\"validation\"]   # ~872\n",
        "ds_test  = sst2[\"test\"]         # sem labels\n",
        "\n",
        "len(ds_train), len(ds_valid), len(ds_test)\n"
      ],
      "metadata": {
        "id": "1iIAfkwq9fw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "pretrained = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizerFast.from_pretrained(pretrained)\n",
        "\n",
        "MAX_LEN = 128\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(\n",
        "        batch[\"sentence\"],\n",
        "        truncation=True,\n",
        "        padding=False,   # padding dinâmico via DataCollator\n",
        "        max_length=MAX_LEN\n",
        "    )\n",
        "\n",
        "ds_train_tok = ds_train.map(tokenize, batched=True, remove_columns=[\"sentence\", \"idx\"])\n",
        "ds_valid_tok = ds_valid.map(tokenize, batched=True, remove_columns=[\"sentence\", \"idx\"])\n",
        "ds_test_tok  = ds_test.map(tokenize,  batched=True, remove_columns=[\"sentence\", \"idx\"])\n",
        "\n",
        "ds_train_tok = ds_train_tok.rename_column(\"label\", \"labels\")\n",
        "ds_valid_tok = ds_valid_tok.rename_column(\"label\", \"labels\")\n",
        "# ds_test não tem \"label\"\n",
        "\n",
        "ds_train_tok.set_format(\"torch\")\n",
        "ds_valid_tok.set_format(\"torch\")\n",
        "ds_test_tok.set_format(\"torch\")\n"
      ],
      "metadata": {
        "id": "G-hQjKJeg_VY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model and Tokenizer\n",
        "modelo_bert_congelado3 = AutoModelForSequenceClassification.from_pretrained(MODEL_CHECKPOINT, num_labels=2)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
        "\n",
        "# 1) Congelar TODAS as camadas inicialmente\n",
        "for param in modelo_bert_congelado3.bert.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 2) Descongelar a partir da camada 10 (10 e 11)\n",
        "for param in modelo_bert_congelado3.bert.encoder.layer[10:].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# (Opcional) também descongelar o pooler\n",
        "for param in modelo_bert_congelado3.bert.pooler.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# O classificador final já vem descongelado por padrão\n",
        "for param in modelo_bert_congelado3.classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "#testa se deu certo\n",
        "for name, param in modelo_bert_congelado3.named_parameters():\n",
        "  if \"encoder.layer.9\" in name:\n",
        "    print(name, \"->\", param.requires_grad)\n",
        "  if \"encoder.layer.10\" in name:\n",
        "    print(name, \"->\", param.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDffnZivebbt",
        "outputId": "6ef131c9-c42d-4ff9-87ad-b3701af501c8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert.encoder.layer.9.attention.self.query.weight -> False\n",
            "bert.encoder.layer.9.attention.self.query.bias -> False\n",
            "bert.encoder.layer.9.attention.self.key.weight -> False\n",
            "bert.encoder.layer.9.attention.self.key.bias -> False\n",
            "bert.encoder.layer.9.attention.self.value.weight -> False\n",
            "bert.encoder.layer.9.attention.self.value.bias -> False\n",
            "bert.encoder.layer.9.attention.output.dense.weight -> False\n",
            "bert.encoder.layer.9.attention.output.dense.bias -> False\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.weight -> False\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.bias -> False\n",
            "bert.encoder.layer.9.intermediate.dense.weight -> False\n",
            "bert.encoder.layer.9.intermediate.dense.bias -> False\n",
            "bert.encoder.layer.9.output.dense.weight -> False\n",
            "bert.encoder.layer.9.output.dense.bias -> False\n",
            "bert.encoder.layer.9.output.LayerNorm.weight -> False\n",
            "bert.encoder.layer.9.output.LayerNorm.bias -> False\n",
            "bert.encoder.layer.10.attention.self.query.weight -> True\n",
            "bert.encoder.layer.10.attention.self.query.bias -> True\n",
            "bert.encoder.layer.10.attention.self.key.weight -> True\n",
            "bert.encoder.layer.10.attention.self.key.bias -> True\n",
            "bert.encoder.layer.10.attention.self.value.weight -> True\n",
            "bert.encoder.layer.10.attention.self.value.bias -> True\n",
            "bert.encoder.layer.10.attention.output.dense.weight -> True\n",
            "bert.encoder.layer.10.attention.output.dense.bias -> True\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.weight -> True\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.bias -> True\n",
            "bert.encoder.layer.10.intermediate.dense.weight -> True\n",
            "bert.encoder.layer.10.intermediate.dense.bias -> True\n",
            "bert.encoder.layer.10.output.dense.weight -> True\n",
            "bert.encoder.layer.10.output.dense.bias -> True\n",
            "bert.encoder.layer.10.output.LayerNorm.weight -> True\n",
            "bert.encoder.layer.10.output.LayerNorm.bias -> True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "treinador3 = Trainer(\n",
        "   model=modelo_bert_congelado3,\n",
        "   args=training_args,\n",
        "   train_dataset=tokenized_train,\n",
        "   eval_dataset=tokenized_test,\n",
        "   tokenizer=tokenizer,\n",
        "   data_collator=data_collator,\n",
        "   compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "treinador.train()"
      ],
      "metadata": {
        "id": "mRAiJJawebIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treinador3.evaluate()"
      ],
      "metadata": {
        "id": "IH2lqLe0gISy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}